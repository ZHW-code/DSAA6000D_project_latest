{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Node Classification"
      ],
      "metadata": {
        "id": "Qq8d8g2ZPwIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import necessary packages"
      ],
      "metadata": {
        "id": "Jck2sQIVP0fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHk-LoLReOk8",
        "outputId": "96fb1a00-9fc8-4a39-dc8d-6b498b569bc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4brnd8SWjt1h",
        "outputId": "40556967-12e8-4eeb-a342-ba7b4ed235ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.9/776.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch_lightning) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.10.0 pytorch_lightning-2.1.2 torchmetrics-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "import torch\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data"
      ],
      "metadata": {
        "id": "M6YKmZyzeHET"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download the Cora Dataset"
      ],
      "metadata": {
        "id": "xk3uVE8CQXQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "CHECKPOINT_PATH = \"saved_models\"\n",
        "gnn_layer_by_name = {\"GCN\": geom_nn.GCNConv}"
      ],
      "metadata": {
        "id": "UwNwVZARlIRP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I. Download the dataset"
      ],
      "metadata": {
        "id": "WW3z_HluQnjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cora_dataset = torch_geometric.datasets.Planetoid(root=\"data\", name=\"Cora\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cr1UXZSecJC",
        "outputId": "c84faed4-aa78-4e0f-9cd0-bfcda26dcfe6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "II. Visualize the dataset"
      ],
      "metadata": {
        "id": "mI438F0SQrDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cora_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xny9S0Ooeii1",
        "outputId": "5fce2366-4d22-44d0-dce3-47874e98e9be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Construction"
      ],
      "metadata": {
        "id": "qz3z75J5Qx3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. GNN Model"
      ],
      "metadata": {
        "id": "zlOCW7eKQ3WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inputs description: c_in: Dimension of input features; c_hidden: Dimension of hidden features; c_out: Dimension of the output features. num_layers: Number of \"hidden\" graph layers; layer_name: String of the graph layer to use; dp_rate:  Dropout rate to apply throughout the network; kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
        "            \n",
        "            \n",
        "            \n",
        "            "
      ],
      "metadata": {
        "id": "m1G_-WkvRA3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
        "        super(GNNModel, self).__init__()\n",
        "\n",
        "        self.gnn_layer = gnn_layer_by_name[layer_name]\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            self.layers.append(self.gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs))\n",
        "            self.layers.append(nn.ReLU(inplace=True))\n",
        "            self.layers.append(nn.Dropout(dp_rate))\n",
        "            in_channels = c_hidden\n",
        "\n",
        "        self.layers.append(self.gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for l in self.layers:\n",
        "            if isinstance(l, geom_nn.MessagePassing):\n",
        "                x = l(x, edge_index) # Add the \"edge_index\" tensor as additional input for graph layers\n",
        "            else:\n",
        "                x = l(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "z2q2puxPraMS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. MLP Model"
      ],
      "metadata": {
        "id": "59OQNlRTSH2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inputs description: c_in: Dimension of input features; c_hidden: Dimension of hidden features; c_out: Dimension of the output features; num_layers: Number of hidden layers; dp_rate: Dropout rate to apply throughout the network\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            "
      ],
      "metadata": {
        "id": "fkACVB-uSM_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
        "        super(MLPModel, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            self.layers.append(nn.Linear(in_channels, out_channels))\n",
        "            self.layers.append(nn.ReLU(inplace=True))\n",
        "            self.layers.append(nn.Dropout(dp_rate))\n",
        "            in_channels = c_hidden\n",
        "\n",
        "        self.layers.append(nn.Linear(in_channels, c_out))\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x) # x: Input features per node\n",
        "        return x"
      ],
      "metadata": {
        "id": "ieYH0PhntdQL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Merge the models into a PyTorch Lightning module and train a node classifier"
      ],
      "metadata": {
        "id": "WqpDgTPhSy7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node_GNN(pl.LightningModule):\n",
        "    def __init__(self, model_name, **model_kwargs):\n",
        "        super(Node_GNN, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        if model_name == \"MLP\":\n",
        "            self.model = MLPModel(**model_kwargs)\n",
        "        else:\n",
        "            self.model = GNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.model(x, edge_index)\n",
        "\n",
        "        if mode == \"train\":\n",
        "            mask = data.train_mask\n",
        "        elif mode == \"val\":\n",
        "            mask = data.val_mask\n",
        "        elif mode == \"test\":\n",
        "            mask = data.test_mask\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown forward mode: {mode}\")\n",
        "\n",
        "        loss = self.loss_module(x[mask], data.y[mask])\n",
        "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Use Adam or SGD optimizer\n",
        "        optimizer = optim.Adam(self.parameters(), lr=0.1)\n",
        "        # optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "poMbPQ-vuKFO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
        "    pl.seed_everything(6100)\n",
        "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"Node\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    # False enable_progress_bar means that epoch size is 1\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir, callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")], accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\", devices=1, max_epochs=200, enable_progress_bar=False)\n",
        "\n",
        "    # NO need of optional logging argument\n",
        "    trainer.logger._default_hp_metric = None\n",
        "\n",
        "    # If pretrained model exists, then load it and skip the training process\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"Node{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        model = Node_GNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything()\n",
        "        model = Node_GNN(model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs)\n",
        "        trainer.fit(model, node_data_loader, node_data_loader)\n",
        "        model = Node_GNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "\n",
        "    # Find better model for the test set\n",
        "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
        "    batch = next(iter(node_data_loader))\n",
        "    batch = batch.to(model.device)\n",
        "    _, train_acc = model.forward(batch, mode=\"train\")\n",
        "    _, val_acc = model.forward(batch, mode=\"val\")\n",
        "    result = {\"train\": train_acc, \"val\": val_acc, \"test\": test_result[0]['test_acc']}\n",
        "    return model, result"
      ],
      "metadata": {
        "id": "3DwlfYUWgcKJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Print the results"
      ],
      "metadata": {
        "id": "K-Crt3HWTrvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "def print_results(result_dict):\n",
        "    if \"train\" in result_dict:\n",
        "        train_acc = (100.0 * result_dict['train'])\n",
        "        print(f\"Train accuracy: {train_acc:4.2f}%\")\n",
        "    if \"val\" in result_dict:\n",
        "        val_acc = (100.0 * result_dict['val'])\n",
        "        print(f\"Validation accuracy: {val_acc:4.2f}%\")\n",
        "    test_acc = (100.0 * result_dict['test'])\n",
        "    print(f\"Test accuracy: {test_acc:4.2f}%\")"
      ],
      "metadata": {
        "id": "J6Grqq05wj8s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_mlp_model, node_mlp_result = train_node_classifier(model_name=\"MLP\", dataset=cora_dataset, c_hidden=16, num_layers=2, dp_rate=0.1)\n",
        "\n",
        "print_results(node_mlp_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdxbsnHvgh6w",
        "outputId": "de6810fc-7d79-4f94-9484-3da90ceeb1e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 6100\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 6100\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: saved_models/NodeMLP/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name        | Type             | Params\n",
            "-------------------------------------------------\n",
            "0 | model       | MLPModel         | 23.1 K\n",
            "1 | loss_module | CrossEntropyLoss | 0     \n",
            "-------------------------------------------------\n",
            "23.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "23.1 K    Total params\n",
            "0.092     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 98.57%\n",
            "Validation accuracy: 50.20%\n",
            "Test accuracy: 52.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\", layer_name=\"GCN\", dataset=cora_dataset, c_hidden=16, num_layers=2, dp_rate=0.1)\n",
        "\n",
        "print_results(node_gnn_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ85fUdYgs2Q",
        "outputId": "0d2bc491-6c38-46d2-9446-faa608c6ab8d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 6100\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 6100\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: saved_models/NodeGNN/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name        | Type             | Params\n",
            "-------------------------------------------------\n",
            "0 | model       | GNNModel         | 23.1 K\n",
            "1 | loss_module | CrossEntropyLoss | 0     \n",
            "-------------------------------------------------\n",
            "23.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "23.1 K    Total params\n",
            "0.092     Total estimated model params size (MB)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 100.00%\n",
            "Validation accuracy: 74.60%\n",
            "Test accuracy: 76.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6iA_rbxVtBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}